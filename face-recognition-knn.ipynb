{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as image\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#will hold the facial data\n",
    "face_data = []\n",
    "#will hold the class id identifying the face\n",
    "face_id = []\n",
    "class_id = 0\n",
    "id_name_dict = {}\n",
    "#browsing through saved faces in directory\n",
    "for file in os.listdir('./data'):\n",
    "    #loading a face into data_item\n",
    "    data_item = np.load('./data/' + file)\n",
    "    #appending into face data\n",
    "    face_data.append(data_item)\n",
    "    id_name_dict[str(class_id)] = str(file).split('.')[0]\n",
    "    #each file is only one person but many faces, so we append same class_id for each face in that file\n",
    "    face_id.append(class_id * np.ones((data_item.shape[0],)))\n",
    "    #incrementing class_id\n",
    "    class_id += 1\n",
    "#converting to array\n",
    "face_data = np.array(face_data)\n",
    "face_id = np.array(face_id)\n",
    "#concatenate, will give same results as flattening / resize, just adjusting shape here\n",
    "f_face = np.concatenate(face_data, axis = 0)\n",
    "f_fid = np.concatenate(face_id, axis = 0).reshape((-1,1))\n",
    "\n",
    "f_face = f_face.reshape((f_face.shape[0],-1 ))\n",
    "f_fid = f_fid.ravel()\n",
    "\n",
    "print(f_face.shape, f_fid.shape)\n",
    "print(id_name_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(query, data):\n",
    "    mydist = np.sqrt(((query - data)**2).sum())\n",
    "    return mydist\n",
    "\n",
    "def KNN(query, training_data, training_class, k):\n",
    "    points = []\n",
    "    for num in range(0,training_data.shape[0]):\n",
    "        curdist = dist(query, training_data[num])\n",
    "        points.append((curdist, training_class[num]))\n",
    "    points = np.array(sorted(points))\n",
    "    arr = points[:k,1]\n",
    "    t = np.unique(arr, return_counts=True)\n",
    "    idx = t[1].argmax()\n",
    "    return t[0][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('./haarcascade_frontalface_alt.xml')\n",
    "while True:\n",
    "    #ret is a return code, frame is the frame captured\n",
    "    ret, frame = capture.read()\n",
    "    #convert to grayscale if needed\n",
    "    grayscale = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    #ret is false if frame was not captured properly, so we ignore that particular frame\n",
    "    if ret == False:\n",
    "        continue\n",
    "    #stores the faces coordinates in rectangle start, width and height\n",
    "    faces = face_cascade.detectMultiScale(grayscale, 1.3, 5)\n",
    "    #iterating over each face detected in that particular frame\n",
    "    for face in faces:\n",
    "        #extracting our values from face\n",
    "        x,y,w,h = face\n",
    "        #offset value to increase our displayed rectangle size\n",
    "        offset = 50\n",
    "        #creating a rectangle using the coordinates known, top-left and bottom-right, color, and width\n",
    "        cv2.rectangle(grayscale, (x - offset, y - offset), (x+w+offset, y+h+offset), (255,255,255), 4)\n",
    "        #Slice of frame to select out face part\n",
    "        face_section = grayscale[y - offset : y + h + offset, x - offset : x + w + offset]\n",
    "        #resizing face section to a particular standard so that we will be able to apply KNN later\n",
    "        face_section = cv2.resize(face_section, (100,100))\n",
    "        flattened = face_section.flatten()\n",
    "        #prediction\n",
    "        mypredict = KNN(flattened, f_face, f_fid, 10)\n",
    "        #making the rectangle and the text over it\n",
    "        cv2.putText(grayscale, str(id_name_dict[str(int(mypredict))]), (x, y - 10),cv2.FONT_HERSHEY_COMPLEX,1,(255,0,0), 2, cv2.LINE_AA)\n",
    "    cv2.imshow(\"Face Detection\", grayscale)\n",
    "    #first and operation basically gets key from user and compares it to binary equivalent of mentioned key\n",
    "    #loop breaks if key matches\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "#releases capture interface\n",
    "capture.release()\n",
    "#closes any windows created, not doing so will cause process to freeze\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
